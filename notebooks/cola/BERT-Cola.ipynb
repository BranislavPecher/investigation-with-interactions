{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cec18e-f630-47b2-8f67-c92103304740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ac4ff-ce67-421d-ac25-678409a31ac6",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e666637c",
   "metadata": {},
   "source": [
    "Note that the code below implements loading of data from new experiments. We also provide pickled data from running our experiments -- loading of this data is at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e51034a-dc0d-4dfa-b9eb-baa61f47fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7641fc74-ba0d-4c9a-8a8c-862072890690",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', '..', 'results', 'stability', 'cola')\n",
    "FACTORS = os.path.join(DATA_PATH, 'factors', 'predictions')\n",
    "GOLDEN = os.path.join(DATA_PATH, 'golden', 'predictions', 'golden_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa87a1ba-8d1b-44d9-9220-890debc26a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failed = 0\n",
    "all = 0 \n",
    "\n",
    "for split in os.listdir(GOLDEN):\n",
    "    split_path = os.path.join(GOLDEN, split)\n",
    "    for label in os.listdir(split_path):\n",
    "        label_path = os.path.join(split_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for run in os.listdir(label_path):\n",
    "                run_path = os.path.join(label_path, run)\n",
    "                if os.path.isdir(run_path):\n",
    "                    evaluation_path = os.path.join(run_path, model_name)\n",
    "                    if os.path.isdir(evaluation_path):\n",
    "                        with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                            data = json.load(file)\n",
    "                        score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                        results.append(score)\n",
    "                        if score < 0.5:\n",
    "                            failed += 1\n",
    "                        all += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec18f11-745c-49e7-9b0e-aa68b5beffa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.38148511322326"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8d03c7-e0af-4adb-a5c4-afde38077884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8468625685824653"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(results) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52115eca-03f7-4fab-b183-ca1c0f00edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 6.1%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {failed / all * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01223a-2375-4260-bf42-735fc8dc1ddf",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e6229-18e4-40f5-94ea-c2715633ad87",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e940ff4-2ed9-454f-8a4b-24fb06998121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'data_split')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        evaluation_path = os.path.join(run_path, model_name)\n",
    "                        if os.path.isdir(evaluation_path):\n",
    "                            with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                data = json.load(file)\n",
    "                            score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                            split_number = int(split.split('_')[1])\n",
    "                            label_number = int(label.split('_')[1])\n",
    "                            run_number = int(run.split('_')[1])\n",
    "                                \n",
    "                            data_split_results['results'].append({\n",
    "                                'score': score,\n",
    "                                'split': split_number,\n",
    "                                'label': label_number,\n",
    "                                'run': run_number,\n",
    "                            })\n",
    "                            if score < 0.5:\n",
    "                                data_split_results['failed'] += 1\n",
    "                            data_split_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e8f5a0-5089-44c8-845b-601be7dda65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 57)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_split_results['results']), data_split_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969fdff-6b78-405a-b7fb-0e0fe8c98c5b",
   "metadata": {},
   "source": [
    "#### Label Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd824752-6d01-488c-8fa3-5f590ceb54d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'label_selection')\n",
    "                                \n",
    "for label in os.listdir(factor_path):\n",
    "    label_path = os.path.join(factor_path, label)\n",
    "    if label.startswith('label_') and os.path.isdir(label_path):\n",
    "        for split in os.listdir(label_path):\n",
    "            split_path = os.path.join(label_path, split)\n",
    "            if split.startswith('split_') and os.path.isdir(split_path):\n",
    "                for run in os.listdir(split_path):\n",
    "                    run_path = os.path.join(split_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        evaluation_path = os.path.join(run_path, model_name)\n",
    "                        if os.path.isdir(evaluation_path):\n",
    "                            with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                data = json.load(file)\n",
    "                            score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                            split_number = int(split.split('_')[1])\n",
    "                            label_number = int(label.split('_')[1])\n",
    "                            run_number = int(run.split('_')[1])\n",
    "                                \n",
    "                            label_results['results'].append({\n",
    "                                'score': score,\n",
    "                                'split': split_number,\n",
    "                                'label': label_number,\n",
    "                                'run': run_number,\n",
    "                            })\n",
    "                            if score < 0.5:\n",
    "                                label_results['failed'] += 1\n",
    "                            label_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b29d7b8-d680-489f-9389-819cd57a906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 60)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_results['results']), label_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceefb20-1522-4174-a9e9-afe06d8b93b4",
   "metadata": {},
   "source": [
    "#### Initialisation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "504b7014-165f-47f0-9abd-0e8fa9af4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialisation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'model_initialisation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for initialisation in os.listdir(label_path):\n",
    "                    initialisation_path = os.path.join(label_path, initialisation)\n",
    "                    if initialisation.startswith('init_') and os.path.isdir(initialisation_path):\n",
    "                        for run in os.listdir(initialisation_path):\n",
    "                            run_path = os.path.join(initialisation_path, run)\n",
    "                            if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                                evaluation_path = os.path.join(run_path, model_name)\n",
    "                                if os.path.isdir(evaluation_path):\n",
    "                                    with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                        data = json.load(file)\n",
    "                                    score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                    split_number = int(split.split('_')[1])\n",
    "                                    label_number = int(label.split('_')[1])\n",
    "                                    run_number = int(run.split('_')[1])\n",
    "                                    initialisation_number = int(initialisation.split('_')[1])\n",
    "                                \n",
    "                                    initialisation_results['results'].append({\n",
    "                                        'score': score,\n",
    "                                        'split': split_number,\n",
    "                                        'label': label_number,\n",
    "                                        'run': run_number,\n",
    "                                        'initialisation': initialisation_number\n",
    "                                    })\n",
    "                                    if score < 0.5:\n",
    "                                        initialisation_results['failed'] += 1\n",
    "                                    initialisation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5688b8c6-dfef-4bb3-8cd9-62a43f9a36be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 122)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initialisation_results['results']), initialisation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e50c-d9f7-47cd-9bd9-16ddc912a02a",
   "metadata": {},
   "source": [
    "#### Order of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ef37a2-39a2-42b4-acec-3b329fa1c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'data_order')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for order in os.listdir(label_path):\n",
    "                    order_path = os.path.join(label_path, order)\n",
    "                    if order.startswith('data_order_') and os.path.isdir(order_path):\n",
    "                        for run in os.listdir(order_path):\n",
    "                            run_path = os.path.join(order_path, run)\n",
    "                            if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                                evaluation_path = os.path.join(run_path, model_name)\n",
    "                                if os.path.isdir(evaluation_path):\n",
    "                                    with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                        data = json.load(file)\n",
    "                                    score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                    split_number = int(split.split('_')[1])\n",
    "                                    label_number = int(label.split('_')[1])\n",
    "                                    run_number = int(run.split('_')[1])\n",
    "                                    order_number = int(order.split('_')[2])\n",
    "                                \n",
    "                                    order_results['results'].append({\n",
    "                                        'score': score,\n",
    "                                        'split': split_number,\n",
    "                                        'label': label_number,\n",
    "                                        'run': run_number,\n",
    "                                        'order': order_number\n",
    "                                    })\n",
    "                                    if score < 0.5:\n",
    "                                        order_results['failed'] += 1\n",
    "                                    order_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9426f389-6df7-4344-b1a6-92a49d1b0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 144)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_results['results']), order_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6d142-3673-4a56-8e6c-9a7a73a0a578",
   "metadata": {},
   "source": [
    "## Compare Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84346a-7c28-47e4-b3da-4a82f1325c62",
   "metadata": {},
   "source": [
    "### Aggregation by investigated factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "685c7e49-b650-45cf-8bba-3412427ca1dc",
   "metadata": {},
   "source": [
    "In this part we use the aggreagtion by the main investigated factor in following way:\n",
    "- select runs where the value of factors only differ in the investigated factor (non-investigated factors have the same value; investigated has 10 values)\n",
    "- calculate mean and standard deviation across the values of investigated factor\n",
    "- results in ~10 000 values of mean and standard deviation\n",
    "- calculate the final performance values as a mean of the pre-calculated many mean values\n",
    "- calculate the instability of factor by calculating mean of the pre-calculated standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7c4be-c20c-48f0-8bcd-86385ddb0798",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a760a547-f859-41a3-907c-0995dbb25b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.728850501178606, 3.552808446953908, 27.433191866430366, 62.958577790344236)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in data_split_results['results']:\n",
    "    # key = f\"split_{value['split']}-label_{value['label']}-run_{value['run']}-adaptation_{value['adaptation']}\"\n",
    "    key = f\"label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if data_split_by_other_factors.get(key, None) is None:\n",
    "        data_split_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        data_split_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10d4bf1d-3086-48c9-b3a9-e673812f69b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 55.72885050117859\n",
      "Investigated factor deviation: 3.170602059302921\n",
      "Other factors deviation: 1.1329082627495337\n",
      "Variability of factor deviation: 1.1341293182370993\n"
     ]
    }
   ],
   "source": [
    "aggregated_data_split = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in data_split_by_other_factors.items():\n",
    "    aggregated_data_split['mean'].append(np.mean(factor_value))\n",
    "    aggregated_data_split['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_data_split['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_data_split['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_data_split['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_data_split['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32c95e17-be3f-4c28-aae5-f29dcc1a54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 5.7%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {data_split_results['failed'] / data_split_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be09fb6-0881-46b5-a38b-5089d22c343e",
   "metadata": {},
   "source": [
    "#### Label Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27c7f681-9273-4b41-b9b2-f2f9f60a976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.318841551236794,\n",
       " 3.7982238015478513,\n",
       " 33.797222394757796,\n",
       " 62.511866867705365)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in label_results['results']:\n",
    "    # key = f\"split_{value['split']}-label_{value['label']}-run_{value['run']}-adaptation_{value['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if label_by_other_factors.get(key, None) is None:\n",
    "        label_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        label_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1ae0034-8795-422f-9f3a-3793907ab6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 56.318841551236794\n",
      "Investigated factor deviation: 3.382363141616169\n",
      "Other factors deviation: 1.184810707005022\n",
      "Variability of factor deviation: 1.2579138338722868\n"
     ]
    }
   ],
   "source": [
    "aggregated_label = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in label_by_other_factors.items():\n",
    "    aggregated_label['mean'].append(np.mean(factor_value))\n",
    "    aggregated_label['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_label['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_label['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_label['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_label['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dcc4a54-bf5b-4286-8d9d-5aa549575e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 6.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {label_results['failed'] / label_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7bda7-e1f6-4674-896b-c5cbb8a3a90f",
   "metadata": {},
   "source": [
    "#### Initialisation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "217682b8-9aa3-4449-b89a-349076ddf6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.067599727931544,\n",
       " 3.4047551740869646,\n",
       " 40.103784378540944,\n",
       " 62.878889497828894)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialisation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in initialisation_results['results']:\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if initialisation_by_other_factors.get(key, None) is None:\n",
    "        initialisation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        initialisation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1788c853-4ee0-4b99-ab57-faf06dd023d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 56.06759972793154\n",
      "Investigated factor deviation: 2.9934868386748574\n",
      "Other factors deviation: 1.4266268813224812\n",
      "Variability of factor deviation: 0.7720946079597077\n"
     ]
    }
   ],
   "source": [
    "aggregated_initialisation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in initialisation_by_other_factors.items():\n",
    "    aggregated_initialisation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_initialisation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_initialisation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_initialisation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_initialisation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_initialisation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39bcfb04-0c58-4286-acb0-3f937dd0dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 6.1%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {initialisation_results['failed'] / initialisation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d6009-41dc-47ae-b87c-2d7d56ddbe55",
   "metadata": {},
   "source": [
    "#### Order of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9694675-4cbe-4a78-bcf3-7b1c22f4eae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.22319751226404, 3.862468695437335, 28.711898900907517, 63.07103411254219)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in order_results['results']:\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if order_by_other_factors.get(key, None) is None:\n",
    "        order_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        order_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf59bb55-675e-4a30-ad18-10d4955dee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 56.22319751226403\n",
      "Investigated factor deviation: 3.345373621105372\n",
      "Other factors deviation: 1.457876127224389\n",
      "Variability of factor deviation: 1.2655974700175976\n"
     ]
    }
   ],
   "source": [
    "aggregated_order = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in order_by_other_factors.items():\n",
    "    aggregated_order['mean'].append(np.mean(factor_value))\n",
    "    aggregated_order['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_order['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_order['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_order['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_order['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5566f82b-e088-4ae6-adab-61701751df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 7.199999999999999%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {order_results['failed'] / order_results['all'] * 100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7ede8a7-30db-465e-a552-88c88a9671cd",
   "metadata": {},
   "source": [
    "# Save Data and Load Pickle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5eb57410-3285-4dc7-ad5e-7ab2d74ae1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = os.path.join('..', '..', 'pickled', 'cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdee3cd9-9742-4b0c-b5ce-44f035bef773",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'BERT-data'), 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'golden': results,\n",
    "        'split': data_split_results,\n",
    "        'label': label_results,\n",
    "        'initialisation': initialisation_results,\n",
    "        'order': order_results,\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca44832-9e39-4502-9813-7b99e4e6f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'BERT-data'), 'rb') as file:\n",
    "    pickled = pickle.load(file)\n",
    "\n",
    "results = pickled['golden']\n",
    "data_split_results = pickled['split']\n",
    "label_results = pickled['label']\n",
    "initialisation_results = pickled['initialisation']\n",
    "order_results = pickled['order']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_PROJECT",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
