{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec2d6d5-be09-433c-8cb1-bf1ef62a374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ac4ff-ce67-421d-ac25-678409a31ac6",
   "metadata": {},
   "source": [
    "# ProtoNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e666637c",
   "metadata": {},
   "source": [
    "Note that the code below implements loading of data from new experiments. We also provide pickled data from running our experiments -- loading of this data is at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e51034a-dc0d-4dfa-b9eb-baa61f47fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ProtoNet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7641fc74-ba0d-4c9a-8a8c-862072890690",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', '..', 'results', 'stability')\n",
    "FACTORS = os.path.join(DATA_PATH, 'factors', 'predictions')\n",
    "GOLDEN = os.path.join(DATA_PATH, 'golden', 'predictions', 'golden_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa87a1ba-8d1b-44d9-9220-890debc26a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failed = 0\n",
    "all = 0 \n",
    "\n",
    "for split in os.listdir(GOLDEN):\n",
    "    split_path = os.path.join(GOLDEN, split)\n",
    "    for label in os.listdir(split_path):\n",
    "        label_path = os.path.join(split_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for run in os.listdir(label_path):\n",
    "                run_path = os.path.join(label_path, run)\n",
    "                if os.path.isdir(run_path):\n",
    "                    for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                        evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                        if os.path.isdir(evaluation_path):\n",
    "                            with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                data = json.load(file)\n",
    "                            score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                            results.append(score)\n",
    "                            if score < 0.5:\n",
    "                                failed += 1\n",
    "                            all += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec18f11-745c-49e7-9b0e-aa68b5beffa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.33655926452433"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8d03c7-e0af-4adb-a5c4-afde38077884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9381398239175368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(results) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1438b3-f077-44ff-822a-eec17860bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {failed / all * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01223a-2375-4260-bf42-735fc8dc1ddf",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e6229-18e4-40f5-94ea-c2715633ad87",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e940ff4-2ed9-454f-8a4b-24fb06998121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'data_split')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                data_split_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    data_split_results['failed'] += 1\n",
    "                                data_split_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "211719f8-1dd2-464e-8963-4168ca8091a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_split_results['results']), data_split_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969fdff-6b78-405a-b7fb-0e0fe8c98c5b",
   "metadata": {},
   "source": [
    "#### Label Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd824752-6d01-488c-8fa3-5f590ceb54d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'label_selection')\n",
    "                                \n",
    "for label in os.listdir(factor_path):\n",
    "    label_path = os.path.join(factor_path, label)\n",
    "    if label.startswith('label_') and os.path.isdir(label_path):\n",
    "        for split in os.listdir(label_path):\n",
    "            split_path = os.path.join(label_path, split)\n",
    "            if split.startswith('split_') and os.path.isdir(split_path):\n",
    "                for run in os.listdir(split_path):\n",
    "                    run_path = os.path.join(split_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                label_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    label_results['failed'] += 1\n",
    "                                label_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21afcd77-4b9c-4689-8855-9ca06490dbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_results['results']), label_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f96fb2-212f-4d90-b854-a3aa5a61ee23",
   "metadata": {},
   "source": [
    "#### Choice of Adaptation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83926646-8db1-40ac-971a-67308a9515d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    adaptation_results['failed'] += 1\n",
    "                                adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12694d49-1702-4477-9142-65dc53858fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adaptation_results['results']), adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fc44b-2cc6-498f-b9e0-bef27e179f74",
   "metadata": {},
   "source": [
    "##### Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b255c2fa-1388-4021-8d5a-99f061a9a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(DATA_PATH, 'adaptation_stable', 'predictions', 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                if adaptation_number > 10:\n",
    "                                    continue\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                stable_adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    stable_adaptation_results['failed'] += 1\n",
    "                                stable_adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86984065-52c1-4a37-a5e0-0f4b1a8344c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stable_adaptation_results['results']), stable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce292504-68cc-48c8-b883-54e5c98602e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stable_adaptation_results['results']), stable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1bd65-1c5e-4866-ac8e-95a1da20f549",
   "metadata": {},
   "source": [
    "##### Unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77666143-3af6-44c3-887c-b8c7ac195fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(DATA_PATH, 'adaptation_unstable', 'predictions', 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                if adaptation_number > 10:\n",
    "                                    continue\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                unstable_adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    unstable_adaptation_results['failed'] += 1\n",
    "                                unstable_adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57f4833e-3984-4f82-af5b-53d3277cd6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unstable_adaptation_results['results']), unstable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca165808-4a06-4f18-8c1c-c6e67c570e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unstable_adaptation_results['results']), unstable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceefb20-1522-4174-a9e9-afe06d8b93b4",
   "metadata": {},
   "source": [
    "#### Initialisation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "504b7014-165f-47f0-9abd-0e8fa9af4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialisation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'model_initialisation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for initialisation in os.listdir(label_path):\n",
    "                    initialisation_path = os.path.join(label_path, initialisation)\n",
    "                    if initialisation.startswith('init_') and os.path.isdir(initialisation_path):\n",
    "                        for run in os.listdir(initialisation_path):\n",
    "                            run_path = os.path.join(initialisation_path, run)\n",
    "                            if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                                for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                                    evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                                    if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                        with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                            data = json.load(file)\n",
    "                                        score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                        split_number = int(split.split('_')[1])\n",
    "                                        label_number = int(label.split('_')[1])\n",
    "                                        run_number = int(run.split('_')[1])\n",
    "                                        adaptation_number = int(evaluation.split('_')[1])\n",
    "                                        initialisation_number = int(initialisation.split('_')[1])\n",
    "                                \n",
    "                                        initialisation_results['results'].append({\n",
    "                                            'score': score,\n",
    "                                            'split': split_number,\n",
    "                                            'label': label_number,\n",
    "                                            'run': run_number,\n",
    "                                            'adaptation': adaptation_number,\n",
    "                                            'initialisation': initialisation_number\n",
    "                                        })\n",
    "                                        if score < 0.5:\n",
    "                                            initialisation_results['failed'] += 1\n",
    "                                        initialisation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f2d116a-bd18-407e-932e-9c356b88bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initialisation_results['results']), initialisation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e50c-d9f7-47cd-9bd9-16ddc912a02a",
   "metadata": {},
   "source": [
    "#### Order of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0ef37a2-39a2-42b4-acec-3b329fa1c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'data_order')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for order in os.listdir(label_path):\n",
    "                    order_path = os.path.join(label_path, order)\n",
    "                    if order.startswith('data_order_') and os.path.isdir(order_path):\n",
    "                        for run in os.listdir(order_path):\n",
    "                            run_path = os.path.join(order_path, run)\n",
    "                            if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                                for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                                    evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                                    if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                        with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                            data = json.load(file)\n",
    "                                        score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                        split_number = int(split.split('_')[1])\n",
    "                                        label_number = int(label.split('_')[1])\n",
    "                                        run_number = int(run.split('_')[1])\n",
    "                                        adaptation_number = int(evaluation.split('_')[1])\n",
    "                                        order_number = int(order.split('_')[2])\n",
    "                                \n",
    "                                        order_results['results'].append({\n",
    "                                            'score': score,\n",
    "                                            'split': split_number,\n",
    "                                            'label': label_number,\n",
    "                                            'run': run_number,\n",
    "                                            'adaptation': adaptation_number,\n",
    "                                            'order': order_number\n",
    "                                        })\n",
    "                                        if score < 0.5:\n",
    "                                            order_results['failed'] += 1\n",
    "                                        order_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "608e4372-ec2f-4ea7-bcbf-85321a28a500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 71)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_results['results']), order_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6d142-3673-4a56-8e6c-9a7a73a0a578",
   "metadata": {},
   "source": [
    "## Compare Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84346a-7c28-47e4-b3da-4a82f1325c62",
   "metadata": {},
   "source": [
    "### Aggregation by investigated factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "685c7e49-b650-45cf-8bba-3412427ca1dc",
   "metadata": {},
   "source": [
    "In this part we use the aggreagtion by the main investigated factor in following way:\n",
    "- select runs where the value of factors only differ in the investigated factor (non-investigated factors have the same value; investigated has 10 values)\n",
    "- calculate mean and standard deviation across the values of investigated factor\n",
    "- results in ~10 000 values of mean and standard deviation\n",
    "- calculate the final performance values as a mean of the pre-calculated many mean values\n",
    "- calculate the instability of factor by calculating mean of the pre-calculated standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce2e32-291e-464c-8ced-4907266ecac7",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acf39373-e93a-43ad-9330-7d5bf26500ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.35404868647417, 0.9714921564083986, 74.39445561012135, 82.51307705805904)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in data_split_results['results']:\n",
    "    # key = f\"split_{value['split']}-label_{value['label']}-run_{value['run']}-adaptation_{value['adaptation']}\"\n",
    "    key = f\"label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if data_split_by_other_factors.get(key, None) is None:\n",
    "        data_split_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        data_split_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38a75628-462c-4483-81aa-ae278211722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.3540486864742\n",
      "Investigated factor deviation: 0.8872246422612884\n",
      "Other factors deviation: 0.28280597758458825\n",
      "Variability of factor deviation: 0.27685776703895165\n"
     ]
    }
   ],
   "source": [
    "aggregated_data_split = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in data_split_by_other_factors.items():\n",
    "    aggregated_data_split['mean'].append(np.mean(factor_value))\n",
    "    aggregated_data_split['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_data_split['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_data_split['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_data_split['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_data_split['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c2bfaa5-b6c3-4ae3-b181-0472e955bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {data_split_results['failed'] / data_split_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3cb5c-a141-4a56-8bf7-6c55c2083812",
   "metadata": {},
   "source": [
    "#### Label Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71099d75-3667-41d7-95fb-d06586a31744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.33393554683644, 1.0346948286989226, 73.18484772249053, 82.73616477096068)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in label_results['results']:\n",
    "    # key = f\"split_{value['split']}-label_{value['label']}-run_{value['run']}-adaptation_{value['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if label_by_other_factors.get(key, None) is None:\n",
    "        label_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        label_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdf7796c-b67a-4612-9a2e-8dca75ec7216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.33393554683646\n",
      "Investigated factor deviation: 0.9591447944681754\n",
      "Other factors deviation: 0.2682594076955213\n",
      "Variability of factor deviation: 0.28048447722421666\n"
     ]
    }
   ],
   "source": [
    "aggregated_label = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in label_by_other_factors.items():\n",
    "    aggregated_label['mean'].append(np.mean(factor_value))\n",
    "    aggregated_label['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_label['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_label['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_label['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_label['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "583356b6-b0b6-4956-bb3b-34d7a85d1886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {label_results['failed'] / label_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e3f69f-1ade-4caa-b6bf-e07b9cfd6637",
   "metadata": {},
   "source": [
    "#### Choice of Adaptation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c13a701-45b2-453c-a806-191225cd0095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.22839090196791, 1.204322610028756, 73.05102461123994, 82.65649200339897)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in adaptation_results['results']:\n",
    "    # key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if adaptation_by_other_factors.get(key, None) is None:\n",
    "        adaptation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        adaptation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91e4f894-9279-4402-8b8a-529022229461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.2283909019679\n",
      "Investigated factor deviation: 0.9421706933669466\n",
      "Other factors deviation: 0.6678830038500373\n",
      "Variability of factor deviation: 0.3415254408608149\n"
     ]
    }
   ],
   "source": [
    "aggregated_adaptation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in adaptation_by_other_factors.items():\n",
    "    aggregated_adaptation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_adaptation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_adaptation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_adaptation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_adaptation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_adaptation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90e913c1-e1bb-4da0-bbf4-2bc7a7901499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {adaptation_results['failed'] / adaptation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f52d8-2f32-4206-bc62-89d523c97437",
   "metadata": {},
   "source": [
    "##### Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ea374e5-b8ee-46bb-91fd-28cc18ebb51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.41238485657219, 0.9758672000628341, 71.33147447754189, 82.56516405329049)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_adaptation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in stable_adaptation_results['results']:\n",
    "    # key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if stable_adaptation_by_other_factors.get(key, None) is None:\n",
    "        stable_adaptation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        stable_adaptation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed41f7cf-a2ab-4c7d-8f90-0aeed00ec349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.4123848565722\n",
      "Investigated factor deviation: 0.6455378802732623\n",
      "Other factors deviation: 0.6299999774736654\n",
      "Variability of factor deviation: 0.37242135501869256\n"
     ]
    }
   ],
   "source": [
    "aggregated_stable_adaptation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in stable_adaptation_by_other_factors.items():\n",
    "    aggregated_stable_adaptation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_stable_adaptation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_stable_adaptation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_stable_adaptation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_stable_adaptation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_stable_adaptation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2508e64e-f0d9-4b46-a9fa-3374d93e85c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {stable_adaptation_results['failed'] / stable_adaptation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68302d1c-c13b-43c9-86e9-5836f851e2cd",
   "metadata": {},
   "source": [
    "##### Unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8785ebe6-1939-4056-965f-4b0846db44ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.22839090196791, 1.204322610028756, 73.05102461123994, 82.65649200339897)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstable_adaptation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in unstable_adaptation_results['results']:\n",
    "    # key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if unstable_adaptation_by_other_factors.get(key, None) is None:\n",
    "        unstable_adaptation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        unstable_adaptation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37d1467b-0ea3-4c21-93d7-5963e3b1222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.2283909019679\n",
      "Investigated factor deviation: 0.9421706933669466\n",
      "Other factors deviation: 0.6678830038500373\n",
      "Variability of factor deviation: 0.3415254408608149\n"
     ]
    }
   ],
   "source": [
    "aggregated_unstable_adaptation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in unstable_adaptation_by_other_factors.items():\n",
    "    aggregated_unstable_adaptation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_unstable_adaptation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_unstable_adaptation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_unstable_adaptation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_unstable_adaptation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_unstable_adaptation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31eac758-0483-4b79-b33e-b5c21f5fa119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {unstable_adaptation_results['failed'] / unstable_adaptation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766ce902-6e47-4718-8d80-c3a10a7352e7",
   "metadata": {},
   "source": [
    "#### Initialisation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3be6710c-2e28-477e-b9dd-af0459871599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.19678577972888, 0.9678733907935632, 73.4165576204774, 82.34979733092058)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialisation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in initialisation_results['results']:\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if initialisation_by_other_factors.get(key, None) is None:\n",
    "        initialisation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        initialisation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4424caf6-0791-4d08-b8f4-65b1d11d61ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.19678577972888\n",
      "Investigated factor deviation: 0.6583951568179297\n",
      "Other factors deviation: 0.6312840284252992\n",
      "Variability of factor deviation: 0.32368996515191717\n"
     ]
    }
   ],
   "source": [
    "aggregated_initialisation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in initialisation_by_other_factors.items():\n",
    "    aggregated_initialisation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_initialisation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_initialisation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_initialisation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_initialisation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_initialisation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5f23cb6-a79c-42a9-bb9c-676d09fbd22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {initialisation_results['failed'] / initialisation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b90f8e-79c0-4d94-a25b-f1e8e96538c4",
   "metadata": {},
   "source": [
    "#### Order of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9554684-dbb7-4edf-9981-0170f73d06dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75.770676117898, 4.508541849545775, 25.392578679324558, 82.13136315914777)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in order_results['results']:\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if order_by_other_factors.get(key, None) is None:\n",
    "        order_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        order_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1dd5f7fe-99bc-49f6-a8aa-2558ec199fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 75.77067611789799\n",
      "Investigated factor deviation: 3.232722235921918\n",
      "Other factors deviation: 2.3712999424630894\n",
      "Variability of factor deviation: 2.0623756053047644\n"
     ]
    }
   ],
   "source": [
    "aggregated_order = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in order_by_other_factors.items():\n",
    "    aggregated_order['mean'].append(np.mean(factor_value))\n",
    "    aggregated_order['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_order['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_order['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_order['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_order['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "485c4a0a-e99f-4aa2-b3da-d788d673bbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.35500000000000004%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {order_results['failed'] / order_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a5d24-70dd-418e-b153-2405923c1490",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "604d5051-db87-4537-ba47-8b191aec1a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = os.path.join('..', '..', 'pickled', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d48ba0c6-8883-417f-8a5c-8cc1c970d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SAVE_PATH, 'ProtoNet-data'), 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'golden': results,\n",
    "        'split': data_split_results,\n",
    "        'label': label_results,\n",
    "        'initialisation': initialisation_results,\n",
    "        'order': order_results,\n",
    "        'adaptation': adaptation_results,\n",
    "        's_adaptation': stable_adaptation_results,\n",
    "        'u_adaptation': unstable_adaptation_results,\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b9ca6-30f8-4049-b1a3-c4a184036c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'ProtoNet-data'), 'rb') as file:\n",
    "    pickled = pickle.load(file)\n",
    "\n",
    "results = pickled['golden']\n",
    "data_split_results = pickled['split']\n",
    "label_results = pickled['label']\n",
    "initialisation_results = pickled['initialisation']\n",
    "order_results = pickled['order']\n",
    "adaptation_results = pickled['adaptation_results']\n",
    "stable_adaptation_results = pickled['s_adaptation']\n",
    "unstable_adaptation_results = pickled['u_adaptation']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_PROJECT",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
