{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec2d6d5-be09-433c-8cb1-bf1ef62a374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ac4ff-ce67-421d-ac25-678409a31ac6",
   "metadata": {},
   "source": [
    "# MAML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e666637c",
   "metadata": {},
   "source": [
    "Note that the code below implements loading of data from new experiments. We also provide pickled data from running our experiments -- loading of this data is at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e51034a-dc0d-4dfa-b9eb-baa61f47fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'MAML'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7641fc74-ba0d-4c9a-8a8c-862072890690",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', '..', 'results', 'stability')\n",
    "FACTORS = os.path.join(DATA_PATH, 'factors', 'predictions')\n",
    "GOLDEN = os.path.join(DATA_PATH, 'golden', 'predictions', 'golden_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa87a1ba-8d1b-44d9-9220-890debc26a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failed = 0\n",
    "all = 0 \n",
    "\n",
    "for split in os.listdir(GOLDEN):\n",
    "    split_path = os.path.join(GOLDEN, split)\n",
    "    for label in os.listdir(split_path):\n",
    "        label_path = os.path.join(split_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for run in os.listdir(label_path):\n",
    "                run_path = os.path.join(label_path, run)\n",
    "                if os.path.isdir(run_path):\n",
    "                    for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                        evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                        if os.path.isdir(evaluation_path):\n",
    "                            with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                data = json.load(file)\n",
    "                            score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                            results.append(score)\n",
    "                            if score < 0.5:\n",
    "                                failed += 1\n",
    "                            all += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec18f11-745c-49e7-9b0e-aa68b5beffa0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.93851098599407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8d03c7-e0af-4adb-a5c4-afde38077884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.342405353448409"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(results) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52115eca-03f7-4fab-b183-ca1c0f00edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.18%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {failed / all * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01223a-2375-4260-bf42-735fc8dc1ddf",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e6229-18e4-40f5-94ea-c2715633ad87",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e940ff4-2ed9-454f-8a4b-24fb06998121",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'data_split')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                data_split_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    data_split_results['failed'] += 1\n",
    "                                data_split_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e8f5a0-5089-44c8-845b-601be7dda65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_split_results['results']), data_split_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3969fdff-6b78-405a-b7fb-0e0fe8c98c5b",
   "metadata": {},
   "source": [
    "#### Label Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd824752-6d01-488c-8fa3-5f590ceb54d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'label_selection')\n",
    "                                \n",
    "for label in os.listdir(factor_path):\n",
    "    label_path = os.path.join(factor_path, label)\n",
    "    if label.startswith('label_') and os.path.isdir(label_path):\n",
    "        for split in os.listdir(label_path):\n",
    "            split_path = os.path.join(label_path, split)\n",
    "            if split.startswith('split_') and os.path.isdir(split_path):\n",
    "                for run in os.listdir(split_path):\n",
    "                    run_path = os.path.join(split_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                label_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    label_results['failed'] += 1\n",
    "                                label_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b29d7b8-d680-489f-9389-819cd57a906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_results['results']), label_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f96fb2-212f-4d90-b854-a3aa5a61ee23",
   "metadata": {},
   "source": [
    "#### Choice of Adaptation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83926646-8db1-40ac-971a-67308a9515d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    adaptation_results['failed'] += 1\n",
    "                                adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f923be-b228-477a-bfbf-434bfadad3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adaptation_results['results']), adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6059a-f4e5-4f16-83a4-6034ae5bc891",
   "metadata": {},
   "source": [
    "##### Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ec19d04-dd29-467e-b7f6-603308a657db",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(DATA_PATH, 'adaptation_stable', 'predictions', 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                stable_adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    stable_adaptation_results['failed'] += 1\n",
    "                                stable_adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f21b4885-319a-4735-81cc-54e926a3927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stable_adaptation_results['results']), stable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fae7b35b-bf5a-44be-a107-d40238aefb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(DATA_PATH, 'adaptation_stable', 'predictions', 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                if adaptation_number > 10:\n",
    "                                    continue\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                stable_adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    stable_adaptation_results['failed'] += 1\n",
    "                                stable_adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e71dc70-4755-4db2-916d-88c364af4aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stable_adaptation_results['results']), stable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27419fd-f014-416e-b116-c9700bf16041",
   "metadata": {},
   "source": [
    "##### Unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d0ca0f-ce08-4d4f-a92b-877214447387",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(DATA_PATH, 'adaptation_unstable', 'predictions', 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                unstable_adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    unstable_adaptation_results['failed'] += 1\n",
    "                                unstable_adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a1a1b69-16cb-4790-b259-95d17495d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unstable_adaptation_results['results']), unstable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7614d6a-014f-4608-bc8e-dfc33bbedd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstable_adaptation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(DATA_PATH, 'adaptation_unstable', 'predictions', 'model_adaptation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for run in os.listdir(label_path):\n",
    "                    run_path = os.path.join(label_path, run)\n",
    "                    if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                        for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                            evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                            if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                if adaptation_number > 10:\n",
    "                                    continue\n",
    "                                with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                    data = json.load(file)\n",
    "                                score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                split_number = int(split.split('_')[1])\n",
    "                                label_number = int(label.split('_')[1])\n",
    "                                run_number = int(run.split('_')[1])\n",
    "                                adaptation_number = int(evaluation.split('_')[1])\n",
    "                                \n",
    "                                unstable_adaptation_results['results'].append({\n",
    "                                    'score': score,\n",
    "                                    'split': split_number,\n",
    "                                    'label': label_number,\n",
    "                                    'run': run_number,\n",
    "                                    'adaptation': adaptation_number\n",
    "                                })\n",
    "                                if score < 0.5:\n",
    "                                    unstable_adaptation_results['failed'] += 1\n",
    "                                unstable_adaptation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6102748-93c4-46e6-90be-a5a07805f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unstable_adaptation_results['results']), unstable_adaptation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceefb20-1522-4174-a9e9-afe06d8b93b4",
   "metadata": {},
   "source": [
    "#### Initialisation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "504b7014-165f-47f0-9abd-0e8fa9af4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialisation_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'model_initialisation')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for initialisation in os.listdir(label_path):\n",
    "                    initialisation_path = os.path.join(label_path, initialisation)\n",
    "                    if initialisation.startswith('init_') and os.path.isdir(initialisation_path):\n",
    "                        for run in os.listdir(initialisation_path):\n",
    "                            run_path = os.path.join(initialisation_path, run)\n",
    "                            if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                                for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                                    evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                                    if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                        with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                            data = json.load(file)\n",
    "                                        score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                        split_number = int(split.split('_')[1])\n",
    "                                        label_number = int(label.split('_')[1])\n",
    "                                        run_number = int(run.split('_')[1])\n",
    "                                        adaptation_number = int(evaluation.split('_')[1])\n",
    "                                        initialisation_number = int(initialisation.split('_')[1])\n",
    "                                \n",
    "                                        initialisation_results['results'].append({\n",
    "                                            'score': score,\n",
    "                                            'split': split_number,\n",
    "                                            'label': label_number,\n",
    "                                            'run': run_number,\n",
    "                                            'adaptation': adaptation_number,\n",
    "                                            'initialisation': initialisation_number\n",
    "                                        })\n",
    "                                        if score < 0.5:\n",
    "                                            initialisation_results['failed'] += 1\n",
    "                                        initialisation_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5688b8c6-dfef-4bb3-8cd9-62a43f9a36be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(initialisation_results['results']), initialisation_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4e50c-d9f7-47cd-9bd9-16ddc912a02a",
   "metadata": {},
   "source": [
    "#### Order of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0ef37a2-39a2-42b4-acec-3b329fa1c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_results = {\n",
    "    'results': [],\n",
    "    'failed': 0,\n",
    "    'all': 0\n",
    "}\n",
    "\n",
    "factor_path = os.path.join(FACTORS, 'data_order')\n",
    "\n",
    "for split in os.listdir(factor_path):\n",
    "    split_path = os.path.join(factor_path, split)\n",
    "    if split.startswith('split_') and os.path.isdir(split_path):\n",
    "        for label in os.listdir(split_path):\n",
    "            label_path = os.path.join(split_path, label)\n",
    "            if label.startswith('label_') and os.path.isdir(label_path):\n",
    "                for order in os.listdir(label_path):\n",
    "                    order_path = os.path.join(label_path, order)\n",
    "                    if order.startswith('data_order_') and os.path.isdir(order_path):\n",
    "                        for run in os.listdir(order_path):\n",
    "                            run_path = os.path.join(order_path, run)\n",
    "                            if run.startswith('run_') and os.path.isdir(run_path) and os.path.exists(os.path.join(run_path, model_name)):  \n",
    "                                for evaluation in os.listdir(os.path.join(run_path, model_name)):\n",
    "                                    evaluation_path = os.path.join(run_path, model_name, evaluation)\n",
    "                                    if evaluation.startswith('evaluation_') and os.path.isdir(evaluation_path):\n",
    "                                        with open(os.path.join(evaluation_path, 'results.json'), 'r') as file:\n",
    "                                            data = json.load(file)\n",
    "                                        score = f1_score(np.array(data['predictions'][0]), np.array(data['predictions'][1]), average='macro')\n",
    "                                \n",
    "                                        split_number = int(split.split('_')[1])\n",
    "                                        label_number = int(label.split('_')[1])\n",
    "                                        run_number = int(run.split('_')[1])\n",
    "                                        adaptation_number = int(evaluation.split('_')[1])\n",
    "                                        order_number = int(order.split('_')[2])\n",
    "                                \n",
    "                                        order_results['results'].append({\n",
    "                                            'score': score,\n",
    "                                            'split': split_number,\n",
    "                                            'label': label_number,\n",
    "                                            'run': run_number,\n",
    "                                            'adaptation': adaptation_number,\n",
    "                                            'order': order_number\n",
    "                                        })\n",
    "                                        if score < 0.5:\n",
    "                                            order_results['failed'] += 1\n",
    "                                        order_results['all'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9426f389-6df7-4344-b1a6-92a49d1b0176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(order_results['results']), order_results['failed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6d142-3673-4a56-8e6c-9a7a73a0a578",
   "metadata": {},
   "source": [
    "## Compare Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84346a-7c28-47e4-b3da-4a82f1325c62",
   "metadata": {},
   "source": [
    "### Aggregation by investigated factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "685c7e49-b650-45cf-8bba-3412427ca1dc",
   "metadata": {},
   "source": [
    "In this part we use the aggreagtion by the main investigated factor in following way:\n",
    "- select runs where the value of factors only differ in the investigated factor (non-investigated factors have the same value; investigated has 10 values)\n",
    "- calculate mean and standard deviation across the values of investigated factor\n",
    "- results in ~10 000 values of mean and standard deviation\n",
    "- calculate the final performance values as a mean of the pre-calculated many mean values\n",
    "- calculate the instability of factor by calculating mean of the pre-calculated standard deviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7c4be-c20c-48f0-8bcd-86385ddb0798",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a760a547-f859-41a3-907c-0995dbb25b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.13179787985224, 0.960591117423806, 67.70128025238081, 82.80579181852798)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in data_split_results['results']:\n",
    "    # key = f\"split_{value['split']}-label_{value['label']}-run_{value['run']}-adaptation_{value['adaptation']}\"\n",
    "    key = f\"label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if data_split_by_other_factors.get(key, None) is None:\n",
    "        data_split_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        data_split_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10d4bf1d-3086-48c9-b3a9-e673812f69b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.13179787985224\n",
      "Investigated factor deviation: 0.846861446560856\n",
      "Other factors deviation: 0.26271632755125723\n",
      "Variability of factor deviation: 0.3695147039568942\n"
     ]
    }
   ],
   "source": [
    "aggregated_data_split = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in data_split_by_other_factors.items():\n",
    "    aggregated_data_split['mean'].append(np.mean(factor_value))\n",
    "    aggregated_data_split['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_data_split['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_data_split['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_data_split['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_data_split['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32c95e17-be3f-4c28-aae5-f29dcc1a54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {data_split_results['failed'] / data_split_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be09fb6-0881-46b5-a38b-5089d22c343e",
   "metadata": {},
   "source": [
    "#### Label Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27c7f681-9273-4b41-b9b2-f2f9f60a976e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.91335822496757, 1.7019957290123289, 30.69186223712283, 82.75265996281263)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in label_results['results']:\n",
    "    # key = f\"split_{value['split']}-label_{value['label']}-run_{value['run']}-adaptation_{value['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if label_by_other_factors.get(key, None) is None:\n",
    "        label_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        label_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1ae0034-8795-422f-9f3a-3793907ab6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 79.91335822496755\n",
      "Investigated factor deviation: 1.1791870196636256\n",
      "Other factors deviation: 0.45101752903065\n",
      "Variability of factor deviation: 1.1414423431519054\n"
     ]
    }
   ],
   "source": [
    "aggregated_label = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in label_by_other_factors.items():\n",
    "    aggregated_label['mean'].append(np.mean(factor_value))\n",
    "    aggregated_label['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_label['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_label['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_label['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_label['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7dcc4a54-bf5b-4286-8d9d-5aa549575e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.06%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {label_results['failed'] / label_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93235f05-9dda-40b5-a83b-a9780ec122f3",
   "metadata": {},
   "source": [
    "#### Choice of Adaptation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d198d417-92a7-4522-82da-fa84489ad7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.96216902291471, 1.245792306016174, 44.53243156871679, 82.68702082537425)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaptation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in adaptation_results['results']:\n",
    "    # key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if adaptation_by_other_factors.get(key, None) is None:\n",
    "        adaptation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        adaptation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9da0500-d9ee-4fce-ac3b-de408c6ba1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 79.96216902291471\n",
      "Investigated factor deviation: 0.4702532002912076\n",
      "Other factors deviation: 1.0362507243324788\n",
      "Variability of factor deviation: 0.5069958911720958\n"
     ]
    }
   ],
   "source": [
    "aggregated_adaptation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in adaptation_by_other_factors.items():\n",
    "    aggregated_adaptation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_adaptation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_adaptation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_adaptation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_adaptation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_adaptation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b93d881-9d15-44da-8e0b-5c9fdd0dc531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.01%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {adaptation_results['failed'] / adaptation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5324b48-224d-4b80-a585-5e96d3f9b062",
   "metadata": {},
   "source": [
    "##### Stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9867f498-adfc-4aa3-936c-1ceff8c3a68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80.18194322090837, 1.0018677723819405, 67.10120180844963, 82.79030958742395)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_adaptation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in stable_adaptation_results['results']:\n",
    "    # key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if stable_adaptation_by_other_factors.get(key, None) is None:\n",
    "        stable_adaptation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        stable_adaptation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab586baa-d526-446a-a39d-cd1259199028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 80.18194322090838\n",
      "Investigated factor deviation: 0.16727928195009548\n",
      "Other factors deviation: 0.9769734381367209\n",
      "Variability of factor deviation: 0.14587520811682386\n"
     ]
    }
   ],
   "source": [
    "aggregated_stable_adaptation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in stable_adaptation_by_other_factors.items():\n",
    "    aggregated_stable_adaptation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_stable_adaptation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_stable_adaptation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_stable_adaptation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_stable_adaptation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_stable_adaptation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a45fa0dd-94b2-445b-9f57-6cb00949a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {stable_adaptation_results['failed'] / stable_adaptation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61671c-654c-4b61-9218-21d336d192f3",
   "metadata": {},
   "source": [
    "##### Unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ead98179-9fdd-4f74-993e-f2d19b6def59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.96216902291471, 1.245792306016174, 44.53243156871679, 82.68702082537425)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unstable_adaptation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in unstable_adaptation_results['results']:\n",
    "    # key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}\"\n",
    "    score = result['score'] * 100\n",
    "    if unstable_adaptation_by_other_factors.get(key, None) is None:\n",
    "        unstable_adaptation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        unstable_adaptation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccc2ed7d-4a66-4293-814e-b107e41eb451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 79.96216902291471\n",
      "Investigated factor deviation: 0.4702532002912076\n",
      "Other factors deviation: 1.0362507243324788\n",
      "Variability of factor deviation: 0.5069958911720958\n"
     ]
    }
   ],
   "source": [
    "aggregated_unstable_adaptation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in unstable_adaptation_by_other_factors.items():\n",
    "    aggregated_unstable_adaptation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_unstable_adaptation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_unstable_adaptation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_unstable_adaptation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_unstable_adaptation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_unstable_adaptation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b0da0b2-85dc-40a9-bb9c-1c6a2232bf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.01%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {unstable_adaptation_results['failed'] / unstable_adaptation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7bda7-e1f6-4674-896b-c5cbb8a3a90f",
   "metadata": {},
   "source": [
    "#### Initialisation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "217682b8-9aa3-4449-b89a-349076ddf6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.98333781937309, 1.6675303758156068, 35.78085286642192, 82.85333506324773)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialisation_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in initialisation_results['results']:\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if initialisation_by_other_factors.get(key, None) is None:\n",
    "        initialisation_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        initialisation_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1788c853-4ee0-4b99-ab57-faf06dd023d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 79.98333781937309\n",
      "Investigated factor deviation: 0.6778194226254843\n",
      "Other factors deviation: 0.8971914391031136\n",
      "Variability of factor deviation: 1.2313674943653004\n"
     ]
    }
   ],
   "source": [
    "aggregated_initialisation = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in initialisation_by_other_factors.items():\n",
    "    aggregated_initialisation['mean'].append(np.mean(factor_value))\n",
    "    aggregated_initialisation['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_initialisation['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_initialisation['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_initialisation['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_initialisation['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39bcfb04-0c58-4286-acb0-3f937dd0dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.075%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {initialisation_results['failed'] / initialisation_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85d6009-41dc-47ae-b87c-2d7d56ddbe55",
   "metadata": {},
   "source": [
    "#### Order of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9694675-4cbe-4a78-bcf3-7b1c22f4eae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.57718227373387, 1.5399444414812988, 35.7990851396949, 82.74664354327439)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_by_other_factors = {}\n",
    "overall_score = []\n",
    "\n",
    "for result in order_results['results']:\n",
    "    key = f\"split_{result['split']}-label_{result['label']}-run_{result['run']}-adaptation_{result['adaptation']}\"\n",
    "    score = result['score'] * 100\n",
    "    if order_by_other_factors.get(key, None) is None:\n",
    "        order_by_other_factors[key] = [score]\n",
    "    else:\n",
    "        order_by_other_factors[key].append(score)\n",
    "    overall_score.append(score)\n",
    "np.mean(overall_score), np.std(overall_score), np.min(overall_score), np.max(overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf59bb55-675e-4a30-ad18-10d4955dee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigated factor mean: 79.57718227373387\n",
      "Investigated factor deviation: 1.0078957943548463\n",
      "Other factors deviation: 0.8268150194809051\n",
      "Variability of factor deviation: 0.8197267069772418\n"
     ]
    }
   ],
   "source": [
    "aggregated_order = {'mean': [], 'std': []}\n",
    "\n",
    "for _, factor_value in order_by_other_factors.items():\n",
    "    aggregated_order['mean'].append(np.mean(factor_value))\n",
    "    aggregated_order['std'].append(np.std(factor_value))\n",
    "\n",
    "print(f\"Investigated factor mean: {np.mean(aggregated_order['mean'])}\")\n",
    "print(f\"Investigated factor deviation: {np.mean(aggregated_order['std'])}\")\n",
    "print(f\"Other factors deviation: {np.std(aggregated_order['mean'])}\")\n",
    "print(f\"Variability of factor deviation: {np.std(aggregated_order['std'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5566f82b-e088-4ae6-adab-61701751df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed percentage of runs: 0.03%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Failed percentage of runs: {order_results['failed'] / order_results['all'] * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d337f5f-eb09-4a73-9815-af97a6759f81",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f39d649-ccc1-4114-a3fc-eb01e8c9e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLE_PATH = os.path.join('..', '..', 'pickled', 'sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60f7457c-9b14-42c4-aaef-211962604774",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'MAML-data'), 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'golden': results,\n",
    "        'split': data_split_results,\n",
    "        'label': label_results,\n",
    "        'initialisation': initialisation_results,\n",
    "        'order': order_results,\n",
    "        'adaptation': adaptation_results,\n",
    "        's_adaptation': stable_adaptation_results,\n",
    "        'u_adaptation': unstable_adaptation_results,\n",
    "    }, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708122a-cc50-428f-958f-4e1d289bbfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PICKLE_PATH, 'MAML-data'), 'rb') as file:\n",
    "    pickled = pickle.load(file)\n",
    "\n",
    "results = pickled['golden']\n",
    "data_split_results = pickled['split']\n",
    "label_results = pickled['label']\n",
    "initialisation_results = pickled['initialisation']\n",
    "order_results = pickled['order']\n",
    "adaptation_results = pickled['adaptation_results']\n",
    "stable_adaptation_results = pickled['s_adaptation']\n",
    "unstable_adaptation_results = pickled['u_adaptation']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_PROJECT",
   "language": "python",
   "name": "nlp_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
